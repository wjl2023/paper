### 什么阻碍了机器理解自然语言
人在理解的过程中，借用了大量的背景知识库。机器更需要苛刻的知识库：1.规模足够大。2.知识库的语义关系足够丰富。3.结构友好。
传统：本体；语义网络；自由文本（非结构化）

### 知识图谱
本质是大规模的语义网络。由大量实体，关系等构成。
三元组---结构化表示形式。
为理解大量的文本知识提供大量的背景知识支撑。

### 知识图谱让机器理解什么
-概念
-一群实例（为什么汇聚）
-词袋（标签）->说明了什么，告诉机器什么
-动词短语（作为指令的意图）
-短文本
-自然语言问题（对问题的理解）
-推理

### 让机器具备什么能力
-归类
-概念化（把具体的东西概念化）
-联想
-推理（完成人的思考）
-归纳

### 知识库
#### Probase and Probase+
-is a关系
-协同过滤机制补全missing links
#### DBPedia and CN-DBPedia

基于上述知识库可以让机器具备语言认知能力

### 为Concept/category构建属性
建立成difining Features->挖掘特征->属性组合
挖掘频繁属性集->用频繁属性集进行剪枝
发现difining features，然后回头对知识库进行补全，然后迭代直到收敛

### 根据给定的实例，推荐适合的实例并且给出解释
如何去model给定的实例背后的语义->用概念分布来表示意图->加入新实体后保持概念分布

### 让机器理解动词短语
人对动词的理解->对于动词短语所能上升的（蕴含的）概念模式来决定
把概念短语上升到概念模板（动词短语->动词模式）->作为先验知识指导机器对动词语义的理解
->收集动词短语后面的知识的先验分布->根据先验分布猜测动词后面的未知词汇
（固定搭配上升到概念模板毫无意义，所以要对固定句和概念化句（conceptualized patterns）进行区分）
->避免极端：过粗或过细->概念（模型）选择：基于MDL。
MDL准则，实际上是假设复杂性（模型复杂度）和假设产生错误的数量之间对的一个折中。MDL 倾向于选择一个产生少量错误而且较短的假设，而不是能完美分类你和训练数据的较长的假设。

### 短语理解
语法不完整的情况下->理解短文本
短文本->恢复成长语句->根据长句子来parse
(顺序敏感；非顺序敏感)

### 词袋
大量词汇放在一起如何理解这堆词语的含义？
词袋概括->用最少的概念标签语义上覆盖词袋（解决矛盾）
噪音容忍；model进一步融合属性关系（原本是is a关系）

### Q&A
自然语言与人进行交互
基于knowledge parse进行自然语言交互：-离线（基于爬取的实例---QA corpora）-在线
在QA的过程中系统能学习到概念的抽取，问题的表达的映射
让机器理解同一问题语义的不同的问题表达形式：从实例级别的理解上升到概念级
->建立起概念模板到知识库位置的关系

### missing isA Facts Inference
-从相似的实例推理
-从相似的概念推理

### open challenges
-common sense knowledge（抽取->不在文本里显式的表达  和  理解）
-reasoning in language understanding

### 特殊领域样本稀疏性问题

### 下一代搜索和推荐

### 常识问题
抽取
大数据方法->基于数据驱动的常识理解

### 基于知识图谱的用户画像

### 过程性问题的知识图谱

### 知识图谱构建语言问题

### 知识图谱的存储
图数据库？->规模很大；负载复杂

### 知识图谱的推荐思路
用知识图谱扩展用户画像


